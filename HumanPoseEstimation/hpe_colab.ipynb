{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8316,"status":"ok","timestamp":1667678818401,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"N4lemQUfZs0d","outputId":"37405826-5fbd-460c-d105-ac65eb3decc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.5 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31.5 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: protobuf\u003c4,\u003e=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: attrs\u003e=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf\u003c4,\u003e=3.11-\u003emediapipe) (1.15.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emediapipe) (0.11.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emediapipe) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emediapipe) (3.0.9)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emediapipe) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver\u003e=1.0.1-\u003ematplotlib-\u003emediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.11\n"]}],"source":["# !pip install mediapipe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3601,"status":"ok","timestamp":1667679051077,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"qyVEhKFRane3","outputId":"1ee06a55-9189-4b5c-e265-f0ce19160eec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n","Requirement already satisfied: numpy\u003e=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n"]}],"source":["# !pip install opencv-python"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1667687854136,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"sbYw77H7W9tI"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import time\n","\n","from PIL import Image\n","import cv2\n","import mediapipe as mp\n","from mediapipe.python.solutions import pose as mp_pose\n","\n","from google.colab.patches import cv2_imshow\n","\n","import torch\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1125,"status":"ok","timestamp":1667687860635,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"wM8K90jXXGno","outputId":"ad1efe17-9763-4216-eefd-601f1cff6545"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 ðŸš€ 2022-11-5 Python-3.7.15 torch-1.12.1+cu113 CPU\n","\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n","Adding AutoShape... \n"]}],"source":["# Model\n","yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n","\n","yolo_model.classes = [0]\n","\n","mp_drawing = mp.solutions.drawing_utils\n","mp_pose = mp.solutions.pose\n"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":625,"status":"ok","timestamp":1667687875446,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"nJuOuQsk3bPw"},"outputs":[],"source":["def findposition(results, img, draw=True):\n","    lmList = []\n","    # if results are available\n","    if results.pose_landmarks:\n","        for lm_id, lm in enumerate(results.pose_landmarks.landmark):\n","            h, w, c = img.shape\n","            # print(lm_id, lm)\n","            # lm contains id, x,y,z, visibility score.\n","            # x,y,z are ratios, to get the pixel values from landmark values,\n","            # need to multiply landmark ratios (x or y) with image shape (w or h)\n","            cx, cy = int(lm.x * w), int(lm.y * h)\n","            # can choose what fields to be stored. Here just include all 5 available fields\n","            lmList.append([lm_id, cx, cy, round(lm.z, 5), round(lm.visibility, 7)])\n","            if draw:\n","                # overlay on existing dots\n","                cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n","\n","    return lmList\n","\n","def findAngle(lmList, img, p1, p2, p3, draw=True):\n","    # get landmarks\n","    x1, y1 = lmList[p1][1:3]\n","    x2, y2 = lmList[p2][1:3]\n","    x3, y3 = lmList[p3][1:3]\n","\n","    # calculate angle (convert radians to degrees)\n","    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n","    if angle \u003c 0:  # if negative angle value, convert to positive\n","        angle += 360\n","    # print('Angle:', angle)\n","\n","    # draw\n","    if draw:\n","        cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 2)  # white line\n","        cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 2)  # white line\n","        cv2.circle(img, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n","        cv2.circle(img, (x1, y1), 15, (0, 0, 255), 1)\n","        cv2.circle(img, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n","        cv2.circle(img, (x2, y2), 15, (0, 0, 255), 1)\n","        cv2.circle(img, (x3, y3), 10, (0, 0, 255), cv2.FILLED)\n","        cv2.circle(img, (x3, y3), 15, (0, 0, 255), 1)\n","        cv2.putText(img, str(int(angle)), (x2 - 50, y2 + 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n","\n","    return angle"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1667687878324,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"XzX84plIXcrV","outputId":"ee87b600-c11e-4da4-8e49-887812198923"},"outputs":[{"name":"stdout","output_type":"stream","text":["(720, 480)\n"]}],"source":["# cap = cv2.VideoCapture('../../../recordings/lego_rover_build_44mins/split/split000.mp4')\n","# cap = cv2.VideoCapture('../../../recordings/lego_rover_build_44mins/split/split001.mp4')\n","# cap = cv2.VideoCapture('../../../recordings/lego_rover_build_44mins/split/split002.mp4')\n","# cap = cv2.VideoCapture('../../../recordings/lego_rover_build_44mins/split/split003.mp4')\n","# cap = cv2.VideoCapture('../../../recordings/lego_rover_build_44mins/split/split004.mp4')\n","cap = cv2.VideoCapture('/content/drive/MyDrive/U/phd/work4_openvino/recordings/lego_rover_build_44mins/split10s/split001.mp4')\n","\n","while cap.isOpened():\n","    success, frame = cap.read()\n","    h, w, _ = frame.shape\n","    size = (w, h)\n","    print(size)\n","    break\n","\n","# webcam\n","# cap = cv2.VideoCapture(0)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1667687890752,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"N51nrpNvbClT"},"outputs":[],"source":["# save video file as output.avi\n","out = cv2.VideoWriter('/content/drive/MyDrive/U/phd/work4_openvino/PycharmProjects/projectCV/HumanPoseEstimation/output/output4.avi', \n","                     cv2.VideoWriter_fourcc(*\"MJPG\"), 20, size)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1667687897062,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"LXBNKFLZ3tmj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1osyXVY6YdlSYQKfy0l_kqNMM7jp5KGiv"},"executionInfo":{"elapsed":121831,"status":"error","timestamp":1667688058241,"user":{"displayName":"Eric Wang","userId":"00961338577919512403"},"user_tz":-630},"id":"ZoSqJuDpXLxt","outputId":"6d1f2c1b-ab09-417b-b2e4-6b6e3cb8738f"},"outputs":[],"source":["\n","while cap.isOpened():\n","    success, frame = cap.read()\n","    if not success:\n","        break\n","\n","    # recolor\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    # make image writable to False to improve prediction performance\n","    image.flags.writeable = False\n","\n","    result = yolo_model(image)\n","\n","    # recolor image back to BGR for rendering\n","    image.flags.writeable = True\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","    print(result.xyxy)\n","\n","    img_list = []\n","    MARGIN = 10\n","\n","    for (xmin, ymin, xmax, ymax, confidence, clas) in result.xyxy[0].tolist():\n","\n","        count_r = 0\n","        count_l = 0\n","        dir_r = 0\n","        dir_l = 0\n","        pTime = 0\n","        frames = []\n","\n","        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n","            # pose prediction\n","            image_crop = image[int(ymin)+MARGIN:int(ymax)+MARGIN, int(xmin)+MARGIN:int(xmax)+MARGIN:]\n","            # results = pose.process(image[int(ymin)+MARGIN:int(ymax)+MARGIN, int(xmin)+MARGIN:int(xmax)+MARGIN:])\n","            results = pose.process(image_crop)\n","\n","            # draw landmarks\n","            mp_drawing.draw_landmarks(image[int(ymin)+MARGIN:int(ymax)+MARGIN, int(xmin)+MARGIN:int(xmax)+MARGIN:],\n","                                      results.pose_landmarks,\n","                                      mp_pose.POSE_CONNECTIONS,\n","                                      mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n","                                      mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n","                                      )\n","            \n","            # img = findpose(img, draw=False)\n","            lmList = findposition(results, image_crop, draw=False)\n","\n","            if len(lmList) != 0:\n","                # right arm\n","                angle_r = findAngle(lmList, image_crop, 12, 14, 16, True)\n","                # convert to percentage - check the tradeoff between range and accuracy\n","                # this is also a place to filter out noise poses\n","                per_r = np.interp(angle_r, (30, 170), (0, 100))  # from () to ()\n","                # bar_r = np.interp(angle_r, (30, 170), (300, 400)) # use angle\n","                bar_r = np.interp(per_r, (40, 100), (300, 400))  # use percentage\n","                print('angle_right_arm {}, percentage {}'.format(angle_r, per_r))\n","\n","                # TODO check: frontal facing, or sideways facing to the camera\n","                # by\n","                # if\n","\n","                # left arm\n","                angle_l = findAngle(lmList, image_crop, 11, 13, 15, True)\n","                # convert to percentage - check tradeoff\n","                per_l = np.interp(angle_l, (30, 170), (0, 100))  # from () to ()\n","                # bar_l = np.interp(angle_l, (30, 170), (300, 400)) # use angle\n","                bar_l = np.interp(per_l, (40, 100), (300, 400))  # use percentage\n","                print('angle_left_arm {}, percentage {}'.format(angle_l, per_l))\n","\n","                # TODO check: scanning (interaction with Viana), or assembling lego (self-work), or browsing lego from table (self-work)\n","                # scanning: percentage \u003e= angle \u003e= 120 AND duration is shorter than 3 seconds\n","                # assembling: angle \u003c= 90 AND duration is longer than 3 seconds\n","                # other self-work: ELSE\n","                # if per_r \u003e= 50:\n","\n","                # TODO: replicate same checks as right arm\n","                color = (255, 0, 0)  # blue\n","\n","                # right arm\n","                if per_r \u003e= 80:\n","                    color = (0, 255, 0)  # green\n","                    if dir_r == 0:\n","                        count_r += 0.5\n","                        dir_r = 1\n","                if per_r \u003c= 40:\n","                    color = (255, 0, 0)  # blue\n","                    if dir_r == 1:\n","                        count_r += 0.5\n","                        dir_r = 0\n","\n","                # left arm\n","                if per_l \u003e= 80:\n","                    color = (0, 255, 0)  # green\n","                    if dir_l == 0:\n","                        count_l += 0.5\n","                        dir_l = 1\n","                if per_l \u003c= 40:\n","                    color = (255, 0, 0)  # blue\n","                    if dir_l == 1:\n","                        count_l += 0.5\n","                        dir_l = 0\n","\n","                print(count_r, count_l)\n","\n","                # use average percentage as bar value\n","                bar_avg = np.mean((bar_r, bar_l))\n","\n","                # display arm counts\n","                cv2.rectangle(image, (300, 25), (400, 50), color, 2)\n","                cv2.rectangle(image, (300, 25), (int(bar_avg), 50), color, cv2.FILLED)\n","                cv2.putText(image, 'R {} L {}'.format(count_r, count_l), (50, 50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0),\n","                            2)\n","\n","                # display fps\n","                cTime = time.time()\n","                fps = 1 / (cTime - pTime)\n","                pTime = cTime\n","                cv2.putText(image, 'FPS {}'.format(str(int(fps))), (50, 90), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n","\n","\n","            img_list.append(image[int(ymin):int(ymax), int(xmin):int(xmax):])\n","\n","        # cv2.imshow('Image', image)\n","        # cv2_imshow(image)\n","\n","        # write to video file\n","        out.write(image)\n","\n","        #\n","        # cv2.imshow('Activity recognition', image)\n","        if cv2.waitKey(0) \u0026 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcpPMbzgaau9"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOi5PbttDOnpesA1K+j1oZ1","mount_file_id":"1yz0YaROIK-WVLzpb9etdhhwLVXycyVWJ","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}